{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30960bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ded859",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bdfa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'Dataset.xlsx'\n",
    "sheet_name = 'GoodDataset'\n",
    "export_good_bad_dataset = False\n",
    "outlier_removal = False\n",
    "\n",
    "if dataset == 'Dataset.xlsx':\n",
    "    num = 0\n",
    "    df = pd.read_excel(f'Dataset/{dataset}', sheet_name=sheet_name)\n",
    "else:\n",
    "    file = dataset.split('-')[0]\n",
    "    num = dataset.split('-')[1].split('.')[0]\n",
    "    df = pd.read_csv(f'Dataset/{dataset}')\n",
    "\n",
    "# with pd.option_context('display.max_rows', 6): display(df)\n",
    "\n",
    "display(df)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "class_count = df['Class'].value_counts()\n",
    "print(class_count)\n",
    "\n",
    "plt.bar(['Low Sweetness', 'High Sweetness'], [class_count[0], class_count[1]])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7e58e",
   "metadata": {},
   "source": [
    "# Fill NaN with Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roundness_mean = df['Roundness'].mean()\n",
    "max_frequency_mean = df['Max Frequency (Hz)'].mean()\n",
    "\n",
    "print(f'Roundness Mean: {roundness_mean}')\n",
    "print(f'Max Frequency (Hz) Mean: {max_frequency_mean}')\n",
    "\n",
    "df['Roundness'].fillna(roundness_mean, inplace=True)\n",
    "df['Max Frequency (Hz)'].fillna(max_frequency_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f41e8",
   "metadata": {},
   "source": [
    "# Features and Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc5b2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature = ['Weight (g)', 'Roundness', 'Lower Petal', 'Max Frequency (Hz)', 'Max Magnitude']\n",
    "X = df[feature]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9a657",
   "metadata": {},
   "source": [
    "# Dataset Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc32144",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e083f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df[feature + ['Sweetness (%Brix)']].corr(), cmap=\"Blues\", square=True, annot=True)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.savefig('pearson_correlation.pdf', dpi=600,bbox_inches='tight') \n",
    "plt.savefig('pearson_correlation.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce0e00",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b055df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_normalized = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_embedded = TSNE(n_components=2, \n",
    "                  learning_rate='auto',\n",
    "                  init='random',\n",
    "                  verbose=1,\n",
    "                  perplexity=3, \n",
    "                  random_state=42).fit_transform(X_normalized)\n",
    "\n",
    "df_tsne = pd.DataFrame({'Dimension 1': X_embedded[:, 0],\n",
    "                        'Dimension 2': X_embedded[:, 1],\n",
    "                        'Class': y})\n",
    "\n",
    "# pd.cut(df['Sweetness (%Brix)'],\n",
    "#                                         bins=[0, 18, 999],\n",
    "#                                         labels=['Low Sweetness', 'High Sweetness'],\n",
    "#                                         right=False)\n",
    "\n",
    "df_tsne['Class'] = ['High Sweetness' if i == 1 else 'Low Sweetness' for i in df_tsne['Class']]\n",
    "\n",
    "palette = [sns.color_palette('RdBu')[1], sns.color_palette('RdBu')[-1]]\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    data=df_tsne,\n",
    "    x='Dimension 1', \n",
    "    y='Dimension 2',\n",
    "    palette=palette,\n",
    "    hue='Class',\n",
    "    s=200,\n",
    "    legend=\"full\",\n",
    ")\n",
    "plt.xlabel('Dimension 1', fontsize=20, labelpad=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.ylabel('Dimension 2', fontsize=20, labelpad=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "\n",
    "plt.savefig('t_sne.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('t_sne.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f90ba",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584896c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=X, \n",
    "            palette=sns.color_palette('Blues'),\n",
    "            width=0.4,\n",
    "            flierprops={'marker': 'o', \n",
    "                        'markersize': 10, \n",
    "                        'markerfacecolor': 'None', \n",
    "                        'markeredgecolor': 'black'})\n",
    "\n",
    "plt.xticks(fontsize=20, rotation=45)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.savefig('box_plot.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('box_plot.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5e0e",
   "metadata": {},
   "source": [
    "# IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(_df, column):\n",
    "    Q1, Q3 = _df[column].quantile(0.25), _df[column].quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    no_outlier = _df[(_df[column] > lower_limit) & (_df[column] < upper_limit)]\n",
    "    \n",
    "    return no_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ee70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outlier = remove_outlier(df, 'Weight (g)')\n",
    "df_no_outlier = remove_outlier(df_no_outlier, 'Roundness')\n",
    "df_no_outlier = remove_outlier(df_no_outlier, 'Max Frequency (Hz)')\n",
    "df_no_outlier = remove_outlier(df_no_outlier, 'Max Magnitude')\n",
    "\n",
    "display(df_no_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=df_no_outlier[feature], \n",
    "            palette=sns.color_palette('Blues'),\n",
    "            width=0.4,\n",
    "            flierprops={'marker': 'o', \n",
    "                        'markersize': 10, \n",
    "                        'markerfacecolor': 'None', \n",
    "                        'markeredgecolor': 'black'})\n",
    "\n",
    "plt.xticks(fontsize=20, rotation=45)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c94c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if outlier_removal:\n",
    "    X = df_no_outlier[feature]\n",
    "    y = df_no_outlier['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd243a55",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962499ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "score = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': 'accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89737e3a",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bcf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "KNN = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_parameter = {\n",
    "    'model__leaf_size': list(range(1, 15)),\n",
    "    'model__n_neighbors': list(range(1, 10, 2)),\n",
    "    'model__p': np.arange(1.0, 3.0, 0.4),\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', KNN)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=KNN_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0,\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('KNN Best Estimator: ', grid_search.best_estimator_)\n",
    "print('KNN Best Parameter: ', grid_search.best_params_)\n",
    "print('KNN Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = grid_search.best_estimator_['model']\n",
    "KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9504c",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "SVM = SVC(probability=True)\n",
    "SVM_parameter = [\n",
    "    {'model__kernel': ['linear'], \n",
    "     'model__C': np.arange(1.0, 3.0, 0.2)},\n",
    "    {'model__kernel': ['rbf'], \n",
    "     'model__C': np.arange(1.0, 3.0, 0.2), \n",
    "     'model__gamma': list(range(1, 10))}\n",
    "]\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', SVM)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=SVM_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('SVM Best Estimator: ', grid_search.best_estimator_)\n",
    "print('SVM Best Parameter: ', grid_search.best_params_)\n",
    "print('SVM Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05085824",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = grid_search.best_estimator_['model']\n",
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba69f7b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR_parameter = [\n",
    "    {'model__solver': ['newton-cg', 'lbfgs', 'sag'], \n",
    "     'model__penalty': ['l2']},\n",
    "    {'model__solver': ['liblinear'], \n",
    "     'model__penalty': ['l1', 'l2']},\n",
    "    {'model__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "]\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', LR)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=LR_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Logistic Regression Best Estimator: ', grid_search.best_estimator_)\n",
    "print('Logistic Regression Best Parameter: ', grid_search.best_params_)\n",
    "print('Logistic Regression Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = grid_search.best_estimator_['model']\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6ed9f",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "DT = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "DT_parameter = {\n",
    "    'model__max_depth': list(range(1, 15)),\n",
    "    'model__max_leaf_nodes': list(range(2, 15))\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', DT)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=DT_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Decision Tree Best Estimator: ', grid_search.best_estimator_)\n",
    "print('Decision Tree Best Parameter: ', grid_search.best_params_)\n",
    "print('Decision Tree Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b57749",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = grid_search.best_estimator_['model']\n",
    "DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc62628",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20482fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "XGB = XGBClassifier(learning_rate=0.02, objective='binary:logistic', nthread=1)\n",
    "XGB_parameter = {\n",
    "    'model__min_child_weight': list(range(1, 5)),\n",
    "    'model__gamma': list(range(1, 3)),\n",
    "    'model__subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'model__n_estimators': [500, 1000],\n",
    "    'model__max_depth': list(range(1, 5))\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', XGB)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=XGB_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('XGBoost Best Estimator: ', grid_search.best_estimator_)\n",
    "print('XGBoost Best Parameter: ', grid_search.best_params_)\n",
    "print('XGBoost Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = grid_search.best_estimator_['model']\n",
    "XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6e731",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "LGBM = LGBMClassifier(learning_rate=0.02, objective='binary', n_jobs=-1, random_state=42)\n",
    "LGBM_parameter = {\n",
    "    'model__num_leaves': list(range(2, 5)),\n",
    "    'model__max_depth': list(range(1, 4)),\n",
    "    'model__n_estimators': [500, 1000],\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', LGBM)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=LGBM_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy', \n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('LightGBM Best Estimator: ', grid_search.best_estimator_)\n",
    "print('LightGBM Best Parameter: ', grid_search.best_params_)\n",
    "print('LightGBM Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = grid_search.best_estimator_['model']\n",
    "LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dba3c1",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "ANN = MLPClassifier(max_iter=50000, random_state=42)\n",
    "ANN_parameter = {\n",
    "    'model__hidden_layer_sizes': [(2, 2), (3, 4), (4, 2), (4, 4)],\n",
    "    'model__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'model__solver': ['lbfgs', 'sgd', 'adam']\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', ANN)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=ANN_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Artificial Neural Network Best Estimator: ', grid_search.best_estimator_)\n",
    "print('Artificial Neural Network Best Parameter: ', grid_search.best_params_)\n",
    "print('Artificial Neural Network Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = grid_search.best_estimator_['model']\n",
    "ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d3d50",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "RF = RandomForestClassifier(criterion='gini', random_state=42)\n",
    "RF_parameter = {\n",
    "    'model__n_estimators': list(range(1, 30)),\n",
    "    'model__max_depth': list(range(1, 15)),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('standard_scaler', standard_scaler), ('model', RF)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=RF_parameter, \n",
    "                           cv=cross_validation, \n",
    "                           scoring=score, \n",
    "                           refit='accuracy',\n",
    "                           n_jobs=-1, \n",
    "                           verbose=0)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Random Forest Best Estimator: ', grid_search.best_estimator_)\n",
    "print('Random Forest Best Parameter: ', grid_search.best_params_)\n",
    "print('Random Forest Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9256dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = grid_search.best_estimator_['model']\n",
    "RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d54729",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = [\n",
    "    ('KNN', KNN),\n",
    "    ('SVM', SVM),\n",
    "    ('LR', LR),\n",
    "    ('DT', DT),\n",
    "    ('XGB', XGB),\n",
    "    ('LGBM', LGBM),\n",
    "    ('ANN', ANN),\n",
    "    ('RF', RF)\n",
    "]\n",
    "VC = VotingClassifier(estimator, \n",
    "                          weights=[0.15, 0.1, 0.05, 0.1, 0.3, 0.1, 0.1, 0.1], \n",
    "                          voting='soft', \n",
    "                          n_jobs=-1)\n",
    "VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2bdc1",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model_name = {\n",
    "    'KNN': 'KNN',\n",
    "    'SVM': 'SVM',\n",
    "    'LR': 'Logistic Regression',\n",
    "    'DT': 'Decision Tree',\n",
    "    'XGB': 'XGBoost',\n",
    "    'LGBM': 'LightGBM',\n",
    "    'ANN': 'ANN',\n",
    "    'RF': 'Random Forest',\n",
    "    'VC': 'Voting Classifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b811d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y_true = {\n",
    "    'index': [],\n",
    "    'no': [],\n",
    "    'value': []\n",
    "}\n",
    "\n",
    "model_y_predict = {\n",
    "    'KNN': [],\n",
    "    'SVM': [],\n",
    "    'LR': [],\n",
    "    'DT': [],\n",
    "    'XGB': [],\n",
    "    'LGBM': [],\n",
    "    'ANN': [],\n",
    "    'RF': [],\n",
    "    'VC': []\n",
    "}\n",
    "\n",
    "model_y_predict_score = {\n",
    "    'KNN': [],\n",
    "    'SVM': [],\n",
    "    'LR': [],\n",
    "    'DT': [],\n",
    "    'XGB': [],\n",
    "    'LGBM': [],\n",
    "    'ANN': [],\n",
    "    'RF': [],\n",
    "    'VC': []\n",
    "}\n",
    "\n",
    "classifier = [\n",
    "    ('KNN', KNN),\n",
    "    ('SVM', SVM),\n",
    "    ('LR', LR),\n",
    "    ('DT', DT),\n",
    "    ('XGB', XGB),\n",
    "    ('LGBM', LGBM),\n",
    "    ('ANN', ANN),\n",
    "    ('RF', RF),\n",
    "    ('VC', VC)\n",
    "]\n",
    "\n",
    "for train_index, test_index in cross_validation.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "    \n",
    "    model_y_true['index'] = np.append(model_y_true['index'], test_index)\n",
    "    model_y_true['no'] = np.append(model_y_true['no'], df.iloc[test_index, 0])\n",
    "    model_y_true['value'] = np.append(model_y_true['value'], y_test)\n",
    "\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train = standard_scaler.fit_transform(X_train)\n",
    "    X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "    for initial, model in classifier:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predict_score = model.predict_proba(X_test)\n",
    "        model_y_predict[initial] = np.append(model_y_predict[initial], y_predict)\n",
    "        model_y_predict_score[initial] = np.append(model_y_predict_score[initial], y_predict_score[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf17222",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b696c",
   "metadata": {},
   "source": [
    "## Accuracy, Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfa47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_report = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "for initial in model_y_predict:\n",
    "    accuracy = accuracy_score(model_y_true['value'], model_y_predict[initial]) * 100\n",
    "    precision = precision_score(model_y_true['value'], model_y_predict[initial]) * 100\n",
    "    recall = recall_score(model_y_true['value'], model_y_predict[initial]) * 100\n",
    "    f1 = f1_score(model_y_true['value'], model_y_predict[initial]) * 100\n",
    "    \n",
    "    report = pd.DataFrame({'Model': [initial_model_name[initial]],\n",
    "                           'Accuracy': [accuracy],\n",
    "                           'Precision': [precision],\n",
    "                           'Recall': [recall],\n",
    "                           'F1': [f1]})\n",
    "    \n",
    "    model_report = pd.concat([model_report, report], axis=0)\n",
    "\n",
    "display(model_report)\n",
    "\n",
    "model_report.to_csv('Model-Report.csv', index=False)\n",
    "\n",
    "model_report = pd.melt(model_report, id_vars=['Model'], var_name='Metric', value_name='Value')\n",
    "\n",
    "plt.figure(figsize=(28, 12))\n",
    "axis = sns.barplot(model_report, \n",
    "            x='Model', \n",
    "            y='Value', \n",
    "            hue='Metric', \n",
    "            palette=sns.color_palette('Blues', 4))\n",
    "\n",
    "axis.set(xlabel=None)\n",
    "plt.xticks(fontsize=20)\n",
    "axis.set(ylabel=None)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.legend(loc='lower left', fontsize=20)\n",
    "\n",
    "plt.savefig('model_report.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('model_report.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f33bb",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5e683",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row, column = 2, 5\n",
    "figure, axis = plt.subplots(nrows=row, ncols=column, figsize=(16, 10))\n",
    "\n",
    "for i, initial in enumerate(model_y_predict):\n",
    "    sns.heatmap(confusion_matrix(model_y_true['value'], \n",
    "                                 model_y_predict[initial]), \n",
    "                ax=axis.flat[i],\n",
    "                cmap='Blues',\n",
    "                square=True, \n",
    "                annot=True)\n",
    "    axis.flat[i].set_title(initial_model_name[initial])\n",
    "    axis.flat[i].set_xlabel('Predicted label')\n",
    "    axis.flat[i].set_ylabel('True label')\n",
    "\n",
    "figure.tight_layout()\n",
    "\n",
    "plt.savefig('confusion_matrix.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('confusion_matrix.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6466caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "color = sns.color_palette('Paired', 9)\n",
    "\n",
    "figure, axis = plt.subplots(nrows=1, ncols=1, figsize=(16, 10))\n",
    "\n",
    "for i, initial in enumerate(model_y_predict):\n",
    "    RocCurveDisplay.from_predictions(model_y_true['value'], \n",
    "                                     model_y_predict_score[initial], \n",
    "                                     color=color[i], \n",
    "                                     name=initial_model_name[initial], \n",
    "                                     linewidth=3, \n",
    "                                     ax=axis)\n",
    "\n",
    "plt.xlabel('False Positive Rate (Positive label: 1)', fontsize=20, labelpad=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.ylabel('True Positive Rate (Positive label: 1)', fontsize=20, labelpad=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "\n",
    "plt.savefig('roc.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('roc.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37367d18",
   "metadata": {},
   "source": [
    "## SHAP Explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c3259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feature)\n",
    "X_test = pd.DataFrame(X_test, columns=feature)\n",
    "\n",
    "for initial, model in classifier:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.KernelExplainer(ANN.predict_proba, X_train)\n",
    "shap_value = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_value[1], X_test, show=False)\n",
    "\n",
    "plt.savefig('shap.pdf', dpi=600, bbox_inches='tight') \n",
    "plt.savefig('shap.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc53eef",
   "metadata": {},
   "source": [
    "# Dependence Dataset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23305f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_prediction = pd.DataFrame({'index': model_y_true['index'],\n",
    "                                 'no': model_y_true['no'],\n",
    "                                 'value': model_y_true['value']})\n",
    "\n",
    "for initial in model_y_predict:\n",
    "    count_prediction[initial] = model_y_predict[initial]\n",
    "\n",
    "count_prediction['Prediction Rate'] = count_prediction.iloc[:, 3:].sum(axis=1) / len(classifier)\n",
    "\n",
    "# display(count_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b51cc",
   "metadata": {},
   "source": [
    "## True Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3474a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prediction = count_prediction[count_prediction['Prediction Rate'] >= 0.5]\n",
    "true_positive_prediction = positive_prediction[positive_prediction['value'] == 1]\n",
    "\n",
    "# display(true_positive_prediction)\n",
    "\n",
    "negative_prediction = count_prediction[count_prediction['Prediction Rate'] < 0.5]\n",
    "true_negative_prediction = negative_prediction[negative_prediction['value'] == 0]\n",
    "\n",
    "# display(false_negative_prediction)\n",
    "\n",
    "true_prediction = pd.concat([true_positive_prediction, true_negative_prediction])\n",
    "\n",
    "display(true_prediction)\n",
    "\n",
    "print('Shape: ', true_prediction.shape)\n",
    "\n",
    "# true_prediction.to_csv(f'TruePrediction-{int(num) + 1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e44ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_dataset = df.loc[true_prediction['index'].tolist(), :]\n",
    "\n",
    "display(good_dataset)\n",
    "\n",
    "if export_good_bad_dataset:\n",
    "    good_dataset.to_csv(f'GoodDataset-{int(num) + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e700b",
   "metadata": {},
   "source": [
    "## False Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63735d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prediction = count_prediction[count_prediction['Prediction Rate'] >= 0.5]\n",
    "false_positive_prediction = positive_prediction[positive_prediction['value'] == 0]\n",
    "\n",
    "# display(true_positive_prediction)\n",
    "\n",
    "negative_prediction = count_prediction[count_prediction['Prediction Rate'] < 0.5]\n",
    "false_negative_prediction = negative_prediction[negative_prediction['value'] == 1]\n",
    "\n",
    "# display(false_negative_prediction)\n",
    "\n",
    "false_prediction = pd.concat([false_positive_prediction, false_negative_prediction])\n",
    "\n",
    "display(false_prediction)\n",
    "\n",
    "print('Shape: ', false_prediction.shape)\n",
    "\n",
    "# false_prediction.to_csv(f'FalsePrediction-{int(num) + 1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dataset = df.loc[false_prediction['index'].tolist(), :]\n",
    "\n",
    "display(bad_dataset)\n",
    "\n",
    "if export_good_bad_dataset:\n",
    "    bad_dataset.to_csv(f'BadDataset-{int(num) + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768af4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
